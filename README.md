# Multimodal Contextual Interactions of Entities: A Modality Circular Fusion Approach for Link Prediction

## Overview
<p align="center">
  <img src="model.jpg" alt="MoCi" width="1000">
</p>

## Requirments
- Python==3.8
- numpy==1.24.3
- pillow==10.2.0
- torch==1.13.0
- tqdm==4.66.1
- wheel==0.41.2

## ğŸ† Code Structure
The code is organized as follows:
```text
â”œâ”€â”€ datasets
â”‚Â Â  â”œâ”€â”€ DB15K
â”‚Â Â  â”œâ”€â”€ MKG-W
â”‚Â Â  â””â”€â”€ MKG-Y
â”‚Â Â  â””â”€â”€ VTJG-I
â”‚Â Â  â””â”€â”€ VTKG-C
â”‚Â Â  â””â”€â”€ WN18RR++
â”‚Â Â  â””â”€â”€ YAGO15K
â”œâ”€â”€ layers
â”‚Â Â  â”œâ”€â”€ __init__
â”‚Â Â  â””â”€â”€ layer
â”œâ”€â”€ models
â”‚Â Â  â”œâ”€â”€ __init__
â”‚Â Â  â””â”€â”€ model
â”œâ”€â”€ utils
â”‚Â Â  â”œâ”€â”€ __init__
â”‚Â Â  â”œâ”€â”€ data_loader
â”‚Â Â  â””â”€â”€ data_util
â”œâ”€â”€ Readme.md
â””â”€â”€ main.py
```

## Implementation Details
Our experiments were conducted on an NVIDIA RTX A6000 GPU with 48GB of RAM, utilizing the PyTorch deep learning framework for implementation. Throughout the training process, we configured the number of training epochs to 1,000, with a batch size of 256, modality embedding dimensions set at 256, and a learning rate of 0.0005. 

## Usage

Model Training

    python main.py 


##  ğŸ¤ Citation
```python
@inproceedings{
  title={},
  author={},
  booktitle={},
  pages={},
  year={}

}
```